{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "¿Por qué son tan importantes los tests (o pruebas)? En primer lugar, porque ofrecen previsibilidad. O, al menos, te ayudan a conseguir una gran previsibilidad. Por desgracia, siempre hay algún error que se cuela en el código. Pero definitivamente queremos que nuestro código sea lo más predecible posible. Lo que no queremos es tener una sorpresa, en otras palabras, que nuestro código se comporte de forma impredecible.\n",
    "\n",
    "Por lo tanto, tenemos que probar nuestro código; tenemos que comprobar que su comportamiento es correcto, que funciona como se espera cuando se trata de casos extremos, que no se cuelga cuando los componentes con los que está hablando están rotos o inalcanzables, que el rendimiento está dentro del rango aceptable, y así sucesivamente.\n",
    "\n",
    "Esta sesión trata de eso: de asegurarte de que tu código está preparado para enfrentarse al aterrador mundo exterior, de que es lo suficientemente rápido y de que puede hacer frente a condiciones inesperadas o excepcionales.\n",
    "\n",
    "En esta sesión, vamos a explorar los siguientes temas:\n",
    "- Directrices generales de pruebas\n",
    "- Pruebas unitarias\n",
    "- Breve mención al desarrollo basado en pruebas\n",
    "\n",
    "Empecemos por entender qué son las pruebas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebe su aplicación\n",
    "Hay muchos tipos diferentes de pruebas, tantos que las empresas suelen tener un departamento dedicado, llamado control de calidad (QA por sus siglás en inglés), formado por personas que se pasan el día probando el software que producen los desarrolladores de la empresa.\n",
    "\n",
    "Para empezar a hacer una primera clasificación, podemos dividir las pruebas en dos grandes categorías: pruebas de caja blanca y pruebas de caja negra. Las pruebas de caja blanca son las que examinan las partes internas del código; lo inspeccionan hasta un nivel muy fino de detalle. En cambio, las pruebas de caja negra son las que consideran el software sometido a prueba como si estuviera dentro de una caja, cuyo interior se ignora.\n",
    "\n",
    "Incluso la tecnología, o el lenguaje utilizado dentro de la caja, no son importantes para las pruebas de caja negra. Lo que hacen es enchufar una entrada en un extremo de la caja y verificar la salida en el otro extremo: eso es todo.\n",
    "\n",
    "También hay una categoría intermedia, llamada prueba de caja gris, que implica probar un sistema de la misma manera que lo hacemos con el enfoque de caja negra, pero teniendo algún conocimiento sobre los algoritmos y las estructuras de datos utilizadas para escribir el software y solo acceso parcial a su código fuente.\n",
    "\n",
    "Hay muchos tipos diferentes de pruebas en estas categorías, cada una de las cuales tiene una finalidad distinta. Para que te hagas una idea, aquí tienes algunas:\n",
    "- **Pruebas frontales:** Se aseguran de que el lado cliente de tu aplicación está exponiendo la información que debería, todos los enlaces, los botones, la publicidad, todo lo que necesita mostrarse al cliente. También pueden verificar que es posible recorrer un determinado camino a través de la interfaz de usuario.\n",
    "- **Pruebas de escenarios:** Hacen uso de historias (o escenarios) que ayudan al probador a resolver un problema complejo o a probar una parte del sistema. \n",
    "- **Pruebas de integración:** Verifican el comportamiento de los distintos componentes de su aplicación cuando trabajan juntos enviando mensajes a través de interfaces.\n",
    "- **Pruebas de humo:** Especialmente útiles cuando despliegas una nueva actualización en tu aplicación. Comprueban si las partes más esenciales y vitales de su aplicación siguen funcionando como deberían y que no se están incendiando. Este término proviene de cuando los ingenieros probaban los circuitos asegurándose de que nada echaba humo.\n",
    "- **Pruebas de aceptación o pruebas de aceptación del usuario (UAT):** Lo que hace un desarrollador con el propietario del producto (por ejemplo, en un entorno SCRUM) para determinar si el trabajo encargado se ha realizado correctamente.\n",
    "- **Pruebas funcionales:** Verifican las características o funcionalidades del software.\n",
    "- **Pruebas destructivas:** Desmontan partes de su sistema, simulando un fallo, para determinar el rendimiento de las partes restantes del sistema. Este tipo de pruebas son muy frecuentes en empresas que necesitan ofrecer un servicio altamente fiable.\n",
    "- **Pruebas de rendimiento:** Su objetivo es verificar el rendimiento del sistema bajo una carga específica de datos o tráfico para que, por ejemplo, los ingenieros puedan comprender mejor los cuellos de botella del sistema que podrían ponerlo de rodillas en una situación de carga pesada, o los que impiden la escalabilidad.\n",
    "- **Pruebas de usabilidad y pruebas de experiencia de usuario (UX):** Su objetivo es comprobar si la interfaz de usuario es sencilla y fácil de entender y utilizar. También pretenden aportar información a los diseñadores para mejorar la UX.\n",
    "- **Pruebas de seguridad y penetración:** Su objetivo es comprobar hasta qué punto el sistema está protegido contra ataques e intrusiones.\n",
    "- **Pruebas unitarias:** Ayudan al desarrollador a escribir el código de forma sólida y coherente, proporcionando la primera línea de retroalimentación y defensa contra errores de codificación, errores de refactorización, etc.\n",
    "- **Pruebas de regresión:** Proporcionan al desarrollador información útil sobre una característica comprometida en el sistema después de una actualización. Algunas de las causas por las que se dice que un sistema tiene una regresión son que resurja un error antiguo, que una característica existente se vea comprometida o que se introduzca un nuevo problema.\n",
    "\n",
    "Se han escrito muchos libros y artículos sobre pruebas, y tenemos que remitirte a esos recursos si te interesa saber más sobre los distintos tipos de pruebas. En esta sesión, nos concentraremos en las pruebas unitarias, ya que son la columna vertebral de la creación de software y forman la gran mayoría de las pruebas que escribe un desarrollador.\n",
    "\n",
    "Probar es un arte, un arte que no se aprende en los libros, me temo. Puedes aprenderte todas las definiciones (y deberías hacerlo) e intentar recopilar todos los conocimientos sobre pruebas que puedas, pero sólo serás capaz de probar tu software correctamente cuando hayas acumulado suficiente experiencia.\n",
    "\n",
    "Cuando tienes problemas para refactorizar un trozo de código, porque cada pequeña cosa que tocas hace saltar por los aires una prueba, aprendes a escribir pruebas menos rígidas y limitantes, que siguen verificando la corrección de tu código pero, al mismo tiempo, te permiten la libertad y la alegría de jugar con él, de darle la forma que quieras.\n",
    "\n",
    "Cuando te llaman con demasiada frecuencia para que corrijas errores inesperados en tu código, aprendes a escribir pruebas más minuciosas, a elaborar una lista más completa de casos extremos y estrategias para hacerles frente antes de que se conviertan en errores.\n",
    "\n",
    "Cuando pasas demasiado tiempo leyendo pruebas e intentando refactorizarlas para cambiar una pequeña característica del código, aprendes a escribir pruebas más sencillas, más cortas y mejor enfocadas.\n",
    "\n",
    "Necesitas ensuciarte las manos y acumular experiencia. Para ello, te recomiendo que estudies la teoría todo lo que puedas y luego experimentes con distintos enfoques. Además, intenta aprender de programadores experimentados; es muy eficaz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La anatomía de una prueba\n",
    "Antes de concentrarnos en las pruebas unitarias, veamos qué es una prueba y cuál es su propósito.\n",
    "\n",
    "Una prueba es un fragmento de código cuyo propósito es verificar algo en nuestro sistema. Puede ser que estemos llamando a una función pasándole dos enteros, que un objeto tenga una propiedad llamada donald_duck, o que cuando hagas un pedido en alguna API, al cabo de un minuto puedas verlo diseccionado en sus elementos básicos, en la base de datos.\n",
    "\n",
    "Por lo general, una prueba se compone de tres secciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Preparación:** Aquí es donde se prepara la escena. Se preparan todos los datos, los objetos y los servicios que se necesitan en los lugares en los que se necesitan para que estén listos para su uso.\n",
    "- **Ejecución:** Aquí es donde se ejecuta la parte de la lógica que se está comprobando. Realizas una acción utilizando los datos y las interfaces que has configurado en la fase de preparación.\n",
    "- **Verificación:** En esta fase verificas los resultados y te aseguras de que se ajustan a tus expectativas. Se comprueba el valor devuelto por una función, que algunos datos están en la base de datos, que otros no, que algunos han cambiado, que se ha realizado una petición HTTP, que ha ocurrido algo, que se ha llamado a un método, etcétera.\n",
    "\n",
    "Aunque las pruebas suelen seguir esta estructura, en un conjunto de pruebas se suelen encontrar algunas otras construcciones que participan en el juego de las pruebas:\n",
    "\n",
    "- **Configuración:** Esto es algo que se encuentra con bastante frecuencia en varias pruebas diferentes. Es una lógica que se puede personalizar para que se ejecute en cada prueba, clase, módulo o incluso en una sesión completa. En esta fase, los desarrolladores suelen establecer conexiones a las bases de datos, tal vez llenarlas con datos que se necesitarán allí para que la prueba tenga sentido, y así sucesivamente.\n",
    "- **Desmontaje:** Es lo opuesto a la configuración; la fase de desmontaje tiene lugar cuando se han ejecutado las pruebas. Al igual que la configuración, se puede personalizar para que se ejecute en cada prueba, clase, módulo o sesión. Normalmente, en esta fase, destruimos los artefactos que se crearon para el conjunto de pruebas y los limpiamos después de nosotros mismos. Esto es importante porque no queremos tener objetos persistentes alrededor y porque ayuda a asegurarnos de que cada prueba comience desde cero.\n",
    "- **Accesorios** Son los datos que se utilizan en las pruebas. Al utilizar un conjunto específico de accesorios, los resultados son predecibles y, por lo tanto, las pruebas pueden realizar verificaciones contra ellos.\n",
    "\n",
    "En esta sesión, usaremos la biblioteca `pytest` de Python. Es una herramienta poderosa que hace que las pruebas sean más fáciles de lo que serían si solo usáramos herramientas de biblioteca estándar. `pytest` proporciona un montón de ayudantes para que la lógica de la prueba pueda centrarse más en la prueba real que en el cableado y la plantilla que la rodea. Verás, cuando lleguemos al código, que una de las características de `pytest` es que los accesorios, la configuración y el desmontaje a menudo se mezclan en uno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directrices de prueba\n",
    "Al igual que el software, las pruebas pueden ser buenas o malas, con toda una gama de matices en el medio. Para escribir buenas pruebas, aquí hay algunas pautas:\n",
    "- **Que sean lo más sencillas posible.** Está bien infringir algunas buenas reglas de codificación, como codificar valores de forma rígida o duplicar código. Las pruebas deben, ante todo, ser lo más legibles posible y fáciles de entender. Cuando las pruebas son difíciles de leer o entender, nunca se puede estar seguro de que realmente se están asegurando de que su código funcione correctamente.\n",
    "- **Las pruebas deben verificar una cosa y solo una cosa.** Es muy importante que sean breves. Está perfectamente bien escribir varias pruebas para ejercitar un solo objeto o función. Sólo asegúrate de que cada prueba tiene un único propósito.\n",
    "- **Las pruebas no deben hacer suposiciones innecesarias al verificar los datos.** Esto es difícil de entender al principio, pero es importante. Verificar que el resultado de una llamada a una función es [1, 2, 3] no es lo mismo que decir que la salida es una lista que contiene los números 1, 2 y 3. En el primero, también estamos asumiendo el orden; En este último, solo suponemos qué elementos están en la lista. Las diferencias a veces son bastante sutiles, pero siguen siendo muy importantes.\n",
    "- **Las pruebas deben ejercitar el \"qué\" en lugar del \"cómo\".** Las pruebas deben centrarse en comprobar lo que se supone que debe hacer una función, en lugar de cómo lo está haciendo. Por ejemplo, concéntrese en el hecho de que una función está calculando la raíz cuadrada de un número (el qué), en lugar de en el hecho de que está llamando a math.sqrt() para hacerlo (el cómo). A menos que estés escribiendo pruebas de rendimiento o tengas una necesidad particular de verificar cómo se realiza una determinada acción, intenta evitar este tipo de pruebas y concéntrate en el qué. Probar el cómo conduce a pruebas restrictivas y dificulta la refactorización. Además, el tipo de prueba que tienes que escribir cuando te concentras en el cómo es más probable que degrade la calidad de tu base de código de prueba cuando modificas tu software con frecuencia.\n",
    "- **Las pruebas deben utilizar el conjunto mínimo de accesorios necesarios para hacer el trabajo.** Este es otro punto crucial. Los accesorios tienden a crecer con el tiempo. También tienden a cambiar de vez en cuando. Si utiliza grandes cantidades de aparatos e ignora las redundancias en las pruebas, la refactorización llevará más tiempo. Detectar insectos será más difícil. Trate de usar un conjunto de accesorios que sea lo suficientemente grande para que la prueba funcione correctamente, pero no más.\n",
    "- **Las pruebas deben ejecutarse lo más rápido posible.** Una buena base de código de pruebas puede acabar siendo mucho más larga que el propio código que se está probando. Varía según la situación y el desarrollador, pero, sea cual sea la longitud, acabará teniendo cientos, si no miles, de pruebas que ejecutar, lo que significa que cuanto más rápido se ejecuten, más rápido podrá volver a escribir código. Cuando se utiliza el desarrollo basado en pruebas (TDD), por ejemplo, las pruebas se ejecutan muy a menudo, por lo que la velocidad es esencial.\n",
    "- **Las pruebas deben utilizar el menor número de recursos posible.** El motivo es que todos los desarrolladores que comprueben tu código deberían poder ejecutar tus pruebas, independientemente de la potencia de su máquina. Puede ser una máquina virtual pequeña o una configuración CircleCI; tus pruebas deben ejecutarse sin consumir demasiados recursos.\n",
    "\n",
    "Dato importante: CircleCI es una de las mayores plataformas de CI/CD (Integración Continua/Entrega Continua) disponibles en la actualidad. Es muy fácil de integrar con servicios como GitHub, por ejemplo. Tienes que añadir alguna configuración (normalmente en forma de archivo) en tu código fuente, y CircleCI ejecutará pruebas cuando se prepare un nuevo código para fusionarlo en el código base actual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas unitarias\n",
    "Ahora que tenemos una idea sobre qué son las pruebas y por qué las necesitamos, vamos a presentar al mejor amigo del desarrollador: la prueba unitaria.\n",
    "\n",
    "Antes de continuar con los ejemplos, permítanos compartir algunas palabras de advertencia: los fundamentos sobre las pruebas unitarias están basada en la metodología planteada en el libro Learn Python Programming, cuyos autores son: Fabrizio Romano y Heinrich Kruger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escribir una prueba unitaria\n",
    "Las pruebas unitarias toman su nombre del hecho de que se utilizan para probar pequeñas unidades de código. Para explicar cómo escribir una prueba unitaria, veamos un fragmento sencillo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_data(source):\n",
    "    data = load_data(source)\n",
    "    cleaned_data = clean_data(data)\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `get_clean_data()` es responsable de obtener datos de la fuente, limpiarlos y devolverlos a la persona que llama. ¿Cómo probamos esta función?\n",
    "\n",
    "Una forma de hacer esto es llamarlo y luego asegurarse de que `load_data()` se llamó una vez con source como único argumento. Luego tenemos que verificar que `clean_data()` se llamó una vez, con un valor de retorno de `load_data`. Y, por último, tendríamos que asegurarnos de que un valor de retorno de `clean_data` es lo que devuelve la función `get_clean_data()` también.\n",
    "\n",
    "Para hacer esto, necesitamos configurar el código fuente y ejecutar este código, y esto puede ser un problema. Una de las reglas de oro de las pruebas unitarias es que cualquier cosa que cruce los límites de su aplicación debe simularse. No queremos hablar con una fuente de datos real, y no queremos ejecutar funciones reales si se están comunicando con algo que no está contenido en nuestra aplicación. Algunos ejemplos serían una base de datos, un servicio de búsqueda, una API externa y un archivo en el sistema de archivos.\n",
    "\n",
    "Necesitamos que estas restricciones actúen como un escudo, de modo que siempre podamos ejecutar nuestras pruebas de forma segura sin temor a destruir algo en una fuente de datos real.\n",
    "\n",
    "Otra razón es que puede ser bastante difícil para un desarrollador reproducir toda la arquitectura en su máquina. Puede requerir la configuración de bases de datos, API, servicios, archivos y carpetas, etc., y esto puede ser difícil, llevar mucho tiempo o, a veces, ni siquiera ser posible.\n",
    "\n",
    "Tener en cuenta que, una interfaz de programación de aplicaciones (API) es un conjunto de herramientas para crear aplicaciones de software. Una API expresa un componente de software en términos de sus operaciones, entrada y salida, y tipos subyacentes. Por ejemplo, si creas un software que necesita interactuar con un servicio de proveedor de datos, es muy probable que tengas que pasar por su API para obtener acceso a los datos.\n",
    "\n",
    "Retornando, en nuestras pruebas unitarias, tenemos que simular todas esas cosas de alguna manera. Las pruebas unitarias deben ser ejecutadas por cualquier desarrollador sin necesidad de que todo el sistema esté configurado en su máquina.\n",
    "\n",
    "Un enfoque diferente, que favorecemos cuando es posible hacerlo, es simular entidades no usando objetos falsos, sino usando objetos de prueba de propósito especial. Por ejemplo, si nuestro código habla con una base de datos, en lugar de falsificar todas las funciones y métodos que hablan con la base de datos y programar los objetos falsos para que devuelvan lo que devolverían los reales, preferimos crear una base de datos de prueba, configurar las tablas y los datos que necesitamos, y luego parchear la configuración de la conexión para que nuestras pruebas ejecuten código real contra la base de datos de prueba. Esto es ventajoso porque si las bibliotecas subyacentes cambian de una manera que introduce un problema en nuestro código, esta metodología detectará este problema. Una prueba se romperá. Una prueba con mocks, por otro lado, continuará ejecutándose felizmente con éxito, porque la interfaz mock no tendría ni idea del cambio en la biblioteca subyacente. Las bases de datos en memoria son excelentes opciones para estos casos.\n",
    "\n",
    "Tener en cuenta que una de las aplicaciones que permite generar una base de datos para realizar pruebas es Django. Dentro del paquete `django.test`, puedes encontrar varias herramientas que te ayudarán a escribir tus pruebas de forma que no tengas que simular el diálogo con una base de datos. Escribiendo las pruebas de esta manera, también podrás comprobar las transacciones, codificaciones y todos los demás aspectos de la programación relacionados con las bases de datos. Otra ventaja de este enfoque consiste en la posibilidad de comprobar cosas que pueden cambiar de una base de datos a otra.\n",
    "\n",
    "A veces, sin embargo, no es posible. Por ejemplo, cuando el software interactúa con una API y no existe una versión de prueba de esa API, tendríamos que simular esa API utilizando falsificaciones. En realidad, la mayoría de las veces acabamos teniendo que utilizar un enfoque híbrido, en el que utilizamos una versión de prueba de aquellas tecnologías que permiten este enfoque, y utilizamos falsificaciones para todo lo demás."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetos mocks y parches\n",
    "En primer lugar, en Python, estos objetos falsos se llaman mocks (simulacros). Hasta la versión 3.3, la librería `mock` era una librería de terceros que básicamente todo proyecto instalaba vía pip pero, desde la versión 3.3, se ha incluido en la librería estándar bajo el módulo `unittest`, y con razón, dada su importancia y lo extendida que está.\n",
    "\n",
    "El acto de reemplazar un objeto o función real (o en general, cualquier pieza de estructura de datos) por un `mock` se denomina `patching`. La librería `mock` proporciona la herramienta `patch`, que puede actuar como un decorador de funciones o clases, e incluso como un gestor de contextos que puedes utilizar para parchear cosas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aserciones\n",
    "La fase de verificación se realiza mediante el uso de aserciones. En la mayoría de los casos, una aserción es una función o método que se puede utilizar para verificar la igualdad entre objetos, así como otras condiciones. Cuando una condición no se cumple, la aserción lanzará una excepción que hará que su prueba falle. Puede encontrar una lista de aserciones en la documentación del módulo `unittest`; sin embargo, cuando utilice `pytest`, normalmente utilizará la sentencia `assert` genérica, que simplifica aún más las cosas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probar un generador CSV\n",
    "Adoptemos ahora un enfoque práctico. Le mostraremos cómo probar un fragmento de código, y tocaremos el resto de los conceptos importantes en torno a las pruebas unitarias en el contexto de este ejemplo.\n",
    "\n",
    "Vamos a escribir una función de exportación que haga lo siguiente: toma una lista de diccionarios, cada uno de los cuales representa a un usuario. Crea un archivo CSV, le pone una cabecera y procede a añadir todos los usuarios que se consideran válidos según algunas reglas. La función recibe tres parámetros: la lista de diccionarios de usuarios, el nombre del fichero CSV que debe crearse y una indicación sobre si debe sobrescribirse un fichero existente con el mismo nombre.\n",
    "\n",
    "Para que se considere válido y se añada al archivo de salida, un diccionario de usuarios debe cumplir los siguientes requisitos: cada usuario debe tener al menos un correo electrónico, un nombre y una edad. También puede haber un cuarto campo que represente el rol, pero es opcional. La dirección de correo electrónico del usuario debe ser válida, el nombre no debe estar vacío y la edad debe ser un número entero comprendido entre 18 y 65 años.\n",
    "\n",
    "Esta es nuestra tarea, así que ahora vamos a mostrarte el código, y luego vamos a analizar las pruebas que escribimos para él. Pero, lo primero es lo primero, en los siguientes fragmentos de código, vamos a utilizar dos bibliotecas de terceros: `Marshmallow` y `Pytest`, ambas debemos instalarlas con `pip` en el terminal.\n",
    "\n",
    "`Marshmallow` es una biblioteca maravillosa que nos proporciona la capacidad de serializar (o volcar, en terminología Marshmallow) y deserializar (o cargar, en terminología Marshmallow) objetos y, lo que es más importante, nos da la capacidad de definir un esquema que podemos utilizar para validar un diccionario de usuario. `Pytest` es una de las mejores piezas de software que hemos visto. Ahora se utiliza en todas partes, y ha sustituido a otras herramientas como `nose`, por ejemplo. Nos proporciona grandes herramientas para escribir hermosas pruebas cortas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from copy import deepcopy\n",
    "from marshmallow import Schema, fields, pre_load\n",
    "from marshmallow.validate import Length, Range\n",
    "\n",
    "class UserSchema(Schema):\n",
    "    \"\"\"Represent a *valid* user. \"\"\"\n",
    "    email = fields.Email(required=True)\n",
    "    name = fields.Str(required=True, validate=Length(min=1))\n",
    "    age = fields.Int(\n",
    "        required=True, validate=Range(min=18, max=65)\n",
    "    )\n",
    "    role = fields.String()\n",
    "    \n",
    "    @pre_load()\n",
    "    def strip_name(self, data, **kwargs):\n",
    "        data_copy = deepcopy(data)\n",
    "        try:\n",
    "            data_copy['name'] = data_copy['name'].strip()\n",
    "        except (AttributeError, KeyError, TypeError):\n",
    "            pass\n",
    "        return data_copy\n",
    "\n",
    "schema = UserSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta primera parte es donde importamos todos los módulos que necesitamos (`os`, `csv` y `deepcopy`), y algunas herramientas de `marshmallow`, y luego definimos el esquema para los usuarios. Como puedes ver, heredamos de `marshmallow.Schema`, y luego establecemos cuatro campos. Tenga en cuenta que estamos usando dos campos de cadena (`Str`), un correo electrónico y un número entero (`Int`). Estos ya nos proporcionarán cierta validación de `marshmallow`. Observe que no hay `required=True` en el campo de rol.\n",
    "\n",
    "Sin embargo, necesitamos agregar un par de bits de código personalizados. Necesitamos agregar validación en la edad para asegurarnos de que el valor esté dentro del rango que queremos. `Marshmallow` lanzará `ValidationError` si no es así. También se encargará de generar un error en caso de que pasemos cualquier cosa que no sea un número entero.\n",
    "\n",
    "También añadimos validación sobre el nombre, porque el hecho de que haya una clave de nombre en un diccionario no garantiza que el valor de ese nombre sea realmente no vacío. Validamos que la longitud del valor del campo sea al menos uno. Observa que no necesitamos añadir nada para el campo email. Esto se debe a que `Marshmallow` lo validará por nosotros.\n",
    "\n",
    "Después de las declaraciones de los campos, escribimos otro método, `strip_name()`, que está decorado con el ayudante de `Marshmallow` `pre_load()`. Este método se ejecutará antes de que `Marshmallow` deserialice (cargue) los datos. Como puedes ver, primero hacemos una copia de los datos, ya que en este contexto no es buena idea trabajar directamente sobre un objeto mutable, y luego nos aseguramos de eliminar los espacios iniciales y finales de `data['name']`. Esa clave representa el campo nombre que acabamos de declarar. Nos aseguramos de hacer esto dentro de un bloque `try/except`, para que la deserialización pueda ejecutarse sin problemas incluso en caso de errores. El método devuelve la copia modificada de los datos, y `Marshmallow` hace el resto.\n",
    "\n",
    "Su funcionamiento interno es bastante sencillo. Si sobreescribir es `False` y el fichero ya existe, lanzamos `IOError` con un mensaje diciendo que el fichero ya existe. En caso contrario, si podemos continuar, simplemente obtenemos la lista de usuarios válidos y se la pasamos a `write_csv()`, que es la responsable de hacer el trabajo.\n",
    "\n",
    "Resulta que codificamos `get_valid_users()` como un generador, ya que no hay necesidad de hacer una lista potencialmente grande para ponerla en un fichero. Podemos validarlos y guardarlos uno a uno. El corazón de la validación es simplemente una delegación a `schema.validate()`, que utiliza el motor de validación de `marshmallow`. Este método devuelve un diccionario, que estará vacío si los datos son válidos según el esquema o, de lo contrario, contendrá información de error. Realmente no nos interesa recoger la información de error para esta tarea, así que simplemente la ignoramos, y nuestra función `is_valid()` simplemente devuelve `True` si el valor de retorno de `schema.validate()` está vacío, y `False` en caso contrario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_users(users):\n",
    "    \"\"\"Yield one valid user at a time from users. \"\"\"\n",
    "    yield from filter(is_valid, users)\n",
    "\n",
    "def is_valid(user):\n",
    "    \"\"\"Return whether or not the user is valid. \"\"\"\n",
    "    return not schema.validate(user)\n",
    "\n",
    "def write_csv(filename, users):\n",
    "    \"\"\"Write a CSV given a filename and a list of users.\n",
    "    The users are assumed to be valid for the given CSV structure.\n",
    "    \"\"\"\n",
    "    fieldnames = ['email', 'name', 'age', 'role']\n",
    "    \n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        for user in users:\n",
    "            writer.writerow(user)\n",
    "\n",
    "def export(filename, users, overwrite=True):\n",
    "    \"\"\"Export a CSV file.\n",
    "    Create a CSV file and fill with valid users. If 'overwrite'\n",
    "    is False and file already exists, raise IOError.\n",
    "    \"\"\"\n",
    "    if not overwrite and os.path.isfile(filename):\n",
    "        raise IOError(f\"'{filename}' already exists.\")\n",
    "    \n",
    "    valid_users = get_valid_users(users)\n",
    "    write_csv(filename, valid_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo, la lógica es sencilla. Definimos la cabecera en `fieldnames`, luego abrimos filename para escribir, y especificamos `newline=''`, que se recomienda en la documentación cuando se trata de archivos CSV. Una vez creado el fichero, obtenemos un objeto escritor utilizando la clase `csv.DictWriter`. Lo bueno de esta herramienta es que es capaz de mapear los diccionarios de usuario a los nombres de campo, por lo que no necesitamos ocuparnos del ordenamiento.\n",
    "\n",
    "Escribimos primero la cabecera, y luego hacemos un bucle sobre los usuarios y los añadimos uno a uno. Tenga en cuenta que esta función asume que recibe una lista de usuarios válidos, y puede romperse si esa suposición es falsa (con los valores por defecto, se rompería si cualquier diccionario de usuario tuviera campos adicionales).\n",
    "\n",
    "Vayamos ahora a la parte interesante: probar nuestra función export().\n",
    "\n",
    "Empecemos por las importaciones: primero traemos algunas herramientas de `unittest.mock`, luego `pytest`. También importamos el módulo `re` de la biblioteca estándar, ya que será necesario en una de las pruebas.\n",
    "\n",
    "Sin embargo, antes de poder escribir las pruebas, tenemos que hacer algunos fixtures. Como verás, un fixture es una función decorada con el decorador `pytest.fixture`. Se ejecutan antes de cada prueba a la que se aplican. En la mayoría de los casos, esperamos que el fixture devuelva algo para que podamos utilizarlo en una prueba. Tenemos algunos requisitos para un diccionario de usuario, así que vamos a escribir un par de usuarios: uno con requisitos mínimos, y otro con requisitos completos. Ambos deben ser válidos.\n",
    "\n",
    "La única diferencia entre los usuarios es la presencia de la clave de rol, pero esperamos que sea suficiente para mostrarle el punto.\n",
    "\n",
    "Observe que en lugar de simplemente declarar diccionarios a nivel de módulo, en realidad hemos escrito dos funciones que devuelven un diccionario, y las hemos decorado con el decorador `@pytest.fixture`. Esto se debe a que cuando declara un diccionario que se supone que se debe usar en sus pruebas a nivel de módulo, debe asegurarse de copiarlo al comienzo de cada prueba. Si no lo haces, es posible que tengas una prueba que lo modifique, y esto afectará a todas las pruebas que la sigan, comprometiendo su integridad. Al usar estos accesorios, `pytest` nos dará un nuevo diccionario en cada ejecución de prueba, por lo que no necesitamos pasar por ese procedimiento de copia. Esto ayuda a respetar el principio de independencia, que dice que cada prueba debe ser autónoma e independiente.\n",
    "\n",
    "Si un aparato devuelve otro tipo en lugar de dict, entonces eso es lo que obtendrá en la prueba.\n",
    "\n",
    "Los accesorios también son componibles, lo que significa que se pueden usar entre sí, lo cual es una característica muy poderosa de `pytest`. Para mostrarte esto, vamos a escribir un `fixture` para una lista de usuarios, en el que ponemos los dos que ya tenemos, más uno que fallaría la validación porque no tiene edad.\n",
    "\n",
    "Ahora tenemos dos usuarios que podemos usar individualmente, y también tenemos una lista de tres usuarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from unittest.mock import patch, mock_open, call\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture\n",
    "def min_user():\n",
    "    \"\"\"Represents a valid user with minimal data. \"\"\"\n",
    "    return {\n",
    "        'email': 'minimal@example.com',\n",
    "        'name': 'Primus Minimus',\n",
    "        'age': 18,\n",
    "    }\n",
    "\n",
    "@pytest.fixture\n",
    "def full_user():\n",
    "    \"\"\"Represents a valid user with full data. \"\"\"\n",
    "    return {\n",
    "        'email': 'full@example.com',\n",
    "        'name': 'Maximus Plenus',\n",
    "        'age': 65,\n",
    "        'role': 'emperor',\n",
    "    }\n",
    "\n",
    "@pytest.fixture\n",
    "def users(min_user, full_user):\n",
    "    \"\"\"List of users, two valid and one invalid. \"\"\"\n",
    "    bad_user = {\n",
    "        'email': 'invalid@example.com',\n",
    "        'name': 'Horribilis',\n",
    "    }\n",
    "    return [min_user, bad_user, full_user]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera ronda de pruebas consistirá en probar cómo validamos a un usuario. Agruparemos todas las pruebas para esta tarea dentro de una clase. Esto ayuda a dar a las pruebas relacionadas un espacio de nombres, un lugar donde estar. Como veremos más adelante, también nos permite declarar fixtures a nivel de clase, que se definen solo para las pruebas que pertenecen a la clase. Una de las ventajas de declarar un aparato a nivel de clase es que puedes anular fácilmente uno con el mismo nombre que esté fuera del alcance de la clase.\n",
    "\n",
    "Comenzamos de manera muy simple asegurándonos de que nuestros accesorios realmente pasen la validación. Esto ayuda a garantizar que nuestro código validará correctamente a los usuarios que sabemos que son válidos, con datos mínimos y completos. Observe que le dimos a cada función de prueba un parámetro que coincide con el nombre de un dispositivo. Esto tiene el efecto de activar el dispositivo para la prueba. Cuando `pytest` ejecuta las pruebas, inspeccionará los parámetros de cada prueba y pasará los valores devueltos de las funciones de fixture correspondientes como argumentos a la prueba.\n",
    "\n",
    "Para este ejercicio, vamos a usar la parametrización, que es una técnica que nos permite ejecutar la misma prueba varias veces, pero alimentándola con datos diferentes. Es muy útil ya que nos permite escribir la prueba una sola vez sin repetición, y el resultado será manejado de forma muy inteligente por `pytest`, que ejecutará todas esas pruebas como si estuvieran realmente separadas, proporcionándonos así mensajes de error claros cuando fallen. Otra solución sería escribir una prueba con un bucle `for` en su interior que recorra todos los datos con los que queremos probar. Sin embargo, la última solución es de mucha menor calidad, ya que el marco no podrá brindarle información específica como si estuviera ejecutando pruebas separadas. Además, si alguna de las iteraciones del bucle `for` fallara, no habría información sobre lo que habría sucedido después de eso, ya que las iteraciones posteriores no sucederían. Finalmente, el cuerpo de la prueba se volvería más difícil de entender, debido a la lógica adicional del bucle `for`. Por lo tanto, la parametrización es una opción muy superior para este caso de uso.\n",
    "\n",
    "Escribimos una prueba para comprobar que la validación falla cuando el usuario es demasiado joven. Según nuestra regla, un usuario es demasiado joven cuando tiene menos de 18 años. Comprobamos todas las edades entre 0 y 17 años, mediante el uso de range().\n",
    "\n",
    "Si echas un vistazo a cómo funciona la parametrización, verás que declaramos el nombre de un objeto, que luego pasamos a la firma del método, y luego especificamos qué valores tomará este objeto. Para cada valor, la prueba se ejecutará una vez. En el caso de esta primera prueba, el nombre del objeto es age, y los valores son todos los devueltos por range(18), es decir, todos los números enteros del 0 al 17. Fíjate en cómo introducimos la edad en el método de prueba, justo después de nosotros mismos.\n",
    "\n",
    "También utilizamos el `min_user` en esta prueba. En este caso, cambiamos la edad dentro del diccionario `min_user` y luego verificamos que el resultado de `is_valid(min_user)` es `False`. Hacemos esto último afirmando el hecho de que no Falso es Verdadero. En `pytest`, así es como se comprueba algo. Simplemente afirmas que algo es verdad. Si ese es el caso, la prueba ha tenido éxito. Si, en cambio, es lo contrario, la prueba fallará.\n",
    "\n",
    "Tenga en cuenta que `pytest` volverá a evaluar la función del dispositivo para cada ejecución de prueba que lo use, por lo que podemos modificar los datos del dispositivo dentro de la prueba sin afectar a ninguna otra prueba.\n",
    "\n",
    "Añadimos otras dos pruebas. Uno se ocupa del otro extremo del espectro, desde los 66 años hasta los 99. Y el segundo, en cambio, se asegura de que la edad no sea válida cuando no es un número entero, por lo que pasamos algunos valores, como una cadena, un float y None, solo para asegurarnos. Fíjate en que la estructura de la prueba es básicamente siempre la misma, pero, gracias a la parametrización, le alimentamos con argumentos de entrada muy diferentes.\n",
    "\n",
    "Ahora que tenemos todos los errores de edad resueltos, agreguemos una prueba que realmente verifique que la edad esté dentro del rango válido.\n",
    "\n",
    "Es tan fácil como eso. Pasamos el rango correcto, de 18 a 65, y eliminamos el not en la aserción. Observe cómo todas las pruebas comienzan con el prefijo `test_`, de modo que `pytest` puede detectarlas y tener un nombre diferente.\n",
    "\n",
    "Se agregan tres a la clase. El primero comprueba si un usuario no es válido cuando falta uno de los campos obligatorios. Tenga en cuenta que en cada ejecución de prueba, se restaura el dispositivo `min_user`, por lo que solo falta un campo por ejecución de prueba, que es la forma adecuada de verificar los campos obligatorios. Simplemente eliminamos la clave del diccionario. Esta vez, el objeto de parametrización toma el campo de nombre y, al observar la primera prueba, ve todos los campos obligatorios en el decorador de parametrización: correo electrónico, nombre y edad.\n",
    "\n",
    "En el segundo, las cosas son un poco diferentes. En lugar de eliminar claves, simplemente las establecemos (una a la vez) en la cadena vacía. Finalmente, en la tercera, verificamos que el nombre sea solo de espacio en blanco.\n",
    "\n",
    "Las pruebas anteriores se encargan de que los campos obligatorios estén ahí y no estén vacíos, y del formato en torno a la clave de nombre de un usuario.\n",
    "\n",
    "Esta vez, la parametrización es un poco más compleja. Definimos dos objetos (correo electrónico y resultado) y luego pasamos una lista de tuplas, en lugar de una simple lista, al decorador. Cada vez que se ejecute la prueba, una de esas tuplas se desempaquetará para rellenar los valores de correo electrónico y resultado, respectivamente. Esto nos permite escribir una prueba para las direcciones de correo electrónico válidas e inválidas, en lugar de dos direcciones separadas. Definimos una dirección de correo electrónico y especificamos el resultado que esperamos de la validación. Las primeras cuatro son direcciones de correo electrónico no válidas, pero las tres últimas son realmente válidas. Hemos utilizado un par de ejemplos con caracteres no ASCII, solo para asegurarnos de que no nos olvidamos de incluir a nuestros amigos de todo el mundo en la validación.\n",
    "\n",
    "Observe cómo se realiza la validación, afirmando que el resultado de la llamada debe coincidir con el resultado que hemos establecido.\n",
    "\n",
    "Escribamos ahora una prueba sencilla para asegurarnos de que la validación falla cuando introducimos el tipo incorrecto en los campos (de nuevo, la edad se ha tratado por separado antes).\n",
    "\n",
    "Pasamos tres valores diferentes, ninguno de los cuales es realmente una cadena. Esta prueba podría ampliarse para incluir más valores, pero, sinceramente, no deberíamos necesitar escribir pruebas como esta. Lo hemos incluido aquí solo para mostrarle lo que es posible, pero normalmente tendría que centrarse en asegurarse de que el código considera tipos válidos aquellos que deben considerarse válidos, y eso debería ser suficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestIsValid:\n",
    "    \"\"\"Test how code verifies whether a user is valid or not. \"\"\"\n",
    "    def test_minimal(self, min_user):\n",
    "        assert is_valid(min_user)\n",
    "    \n",
    "    def test_full(self, full_user):\n",
    "        assert is_valid(full_user)\n",
    "\n",
    "    @pytest.mark.parametrize('age', range(18))\n",
    "    def test_invalid_age_too_young(self, age, min_user):\n",
    "        min_user['age'] = age\n",
    "        assert not is_valid(min_user)\n",
    "\n",
    "    @pytest.mark.parametrize('age', range(66, 100))\n",
    "    def test_invalid_age_too_old(self, age, min_user):\n",
    "        min_user['age'] = age\n",
    "        assert not is_valid(min_user)\n",
    "    \n",
    "    @pytest.mark.parametrize('age', ['NaN', 3.1415, None])\n",
    "    def test_invalid_age_wrong_type(self, age, min_user):\n",
    "        min_user['age'] = age\n",
    "        assert not is_valid(min_user)\n",
    "\n",
    "    @pytest.mark.parametrize('age', range(18, 66))\n",
    "    def test_valid_age(self, age, min_user):\n",
    "        min_user['age'] = age\n",
    "        assert is_valid(min_user)\n",
    "\n",
    "    @pytest.mark.parametrize('field', ['email', 'name', 'age'])\n",
    "    def test_mandatory_fields(self, field, min_user):\n",
    "        del min_user[field]\n",
    "        assert not is_valid(min_user)\n",
    "\n",
    "    @pytest.mark.parametrize('field', ['email', 'name', 'age'])\n",
    "    def test_mandatory_fields_empty(self, field, min_user):\n",
    "        min_user[field] = ''\n",
    "        assert not is_valid(min_user)\n",
    "    \n",
    "    def test_name_whitespace_only(self, min_user):\n",
    "        min_user['name'] = ' \\n\\t'\n",
    "        assert not is_valid(min_user)\n",
    "\n",
    "    @pytest.mark.parametrize(\n",
    "        'email, outcome',\n",
    "        [\n",
    "            ('missing_at.com', False),\n",
    "            ('@missing_start.com', False),\n",
    "            ('missing_end@', False),\n",
    "            ('missing_dot@example', False),\n",
    "            ('good.one@example.com', True),\n",
    "            ('δοκιμή@παράδειγμα.δοκιμή', True),\n",
    "            ('аджай@экзампл.рус', True),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    def test_email(self, email, outcome, min_user):\n",
    "        min_user['email'] = email\n",
    "        assert is_valid(min_user) == outcome\n",
    "\n",
    "    @pytest.mark.parametrize(\n",
    "        'field, value',\n",
    "        [\n",
    "            ('email', None),\n",
    "            ('email', 3.1415),\n",
    "            ('email', {}),\n",
    "            ('name', None),\n",
    "            ('name', 3.1415),\n",
    "            ('name', {}),\n",
    "            ('role', None),\n",
    "            ('role', 3.1415),\n",
    "            ('role', {}),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    def test_invalid_types(self, field, value, min_user):\n",
    "        min_user[field] = value\n",
    "        assert not is_valid(min_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Límites y granularidad\n",
    "Al comprobar la edad, escribimos tres pruebas para cubrir los tres rangos: 0-17 (fallo), 18-65 (éxito), y 66-99 (fallo). ¿Por qué hemos hecho esto? La respuesta está en el hecho de que estamos tratando con dos límites: 18 y 65. Por lo tanto, nuestras pruebas deben centrarse en las tres regiones que definen esos dos límites: antes de los 18, entre los 18 y los 65, y después de los 65. La forma de hacerlo no es crucial, siempre y cuando te asegures de que compruebas los límites correctamente. Esto significa que si alguien cambia la validación en el esquema de 18 <= valor <= 65 a 18 <= valor < 65 (observe que el segundo <= es ahora <), debe haber una prueba que falle en 65.\n",
    "\n",
    "Este concepto se conoce como límite, y es muy importante que los reconozcas en tu código para que puedas hacer pruebas contra ellos.\n",
    "\n",
    "Otra cosa importante es entender qué nivel de zoom queremos para acercarnos a los límites. En otras palabras, ¿qué unidad debo utilizar para moverme alrededor de ellos?\n",
    "\n",
    "En el caso de la edad, estamos tratando con números enteros, por lo que una unidad de 1 será la elección perfecta (por eso usamos 16, 17, 18, 19, 20, ...). Pero, ¿qué pasaría si estuvieras probando una marca de tiempo? Bueno, en ese caso, es probable que la granularidad correcta sea diferente. Si el código tiene que actuar de manera diferente según la marca de tiempo y esa marca de tiempo representa segundos, la granularidad de las pruebas debe reducirse a segundos. Si la marca de tiempo representa años, entonces los años deben ser la unidad que utilice. Esperamos que te hagas una idea. Este concepto se conoce como granularidad y debe combinarse con el de los límites, de modo que al rodear los límites con la granularidad correcta, puede asegurarse de que sus pruebas no dejan nada al azar.\n",
    "\n",
    "Continuemos ahora con nuestro ejemplo y probemos la función de exportación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba de la función de exportación\n",
    "Vamos a definir otra clase que representa un conjunto de pruebas para la función export().\n",
    "\n",
    "Empecemos por analizar los fixtures. Esta vez los hemos definido a nivel de clase, lo que significa que estarán activos solo mientras se ejecuten las pruebas de la clase. No necesitamos estos dispositivos fuera de esta clase, por lo que no tiene sentido declararlos a nivel de módulo como hemos hecho con los de usuario.\n",
    "\n",
    "Por lo tanto, necesitamos dos archivos. Si recuerdas lo que escribimos al principio de este capítulo, cuando se trata de la interacción con bases de datos, discos, redes, etc., deberíamos simular todo. Sin embargo, cuando sea posible, preferimos utilizar una técnica diferente. En este caso, emplearemos carpetas temporales, que se crearán y eliminarán dentro del dispositivo. Para crear carpetas temporales, empleamos el fixture `tmp_path`, de `pytest`, que es un objeto `pathlib.Path`.\n",
    "\n",
    "Ahora, el primer fixture, `csv_file`, proporciona una referencia a una carpeta temporal. Podemos considerar la lógica hasta el rendimiento como la fase de configuración. El fixture en sí, en términos de datos, está representado por el nombre del archivo temporal. El archivo en sí no está presente todavía. Cuando se ejecuta una prueba, se crea el fixture y, al final de la prueba, se ejecuta el resto del código del fixture (la parte posterior al rendimiento, si la hay). Esa parte puede considerarse la fase de desmontaje. En el caso del fixture `csv_file`, consiste en salir del cuerpo de la función, lo que significa que se borra la carpeta temporal, junto con todo su contenido. Puedes poner mucho más en cada fase de cualquier fixture, y con experiencia, dominarás el arte de hacer setup y teardown de esta manera. En realidad, se vuelve muy natural con bastante rapidez.\n",
    "\n",
    "El segundo fixture es muy similar al primero, pero lo usaremos para probar que podemos evitar sobrescribir cuando llamamos a export con `overwrite=False`. Entonces, creamos un archivo en la carpeta temporal y ponemos algo de contenido en él, solo para tener los medios para verificar que no se ha tocado.\n",
    "\n",
    "Esta prueba emplea los fixtures `users` y `csv_file`, e inmediatamente llama a `export()` con ellos. Esperamos que se haya creado un fichero, y que se haya rellenado con los dos usuarios válidos que tenemos (recuerda que la lista contiene tres usuarios, pero uno no es válido).\n",
    "\n",
    "Para comprobarlo, abrimos el archivo temporal y recogemos todo su texto en una cadena. A continuación, comparamos el contenido del archivo con lo que esperamos que contenga. Observa que sólo hemos puesto la cabecera, y los dos usuarios válidos, en el orden correcto.\n",
    "\n",
    "Ahora necesitamos otra prueba para asegurarnos de que si hay una coma en uno de los valores, nuestro CSV se sigue generando correctamente. Al ser un archivo de valores separados por comas (CSV por sus siglás en inglés), tenemos que asegurarnos de que una coma en los datos no rompe las cosas.\n",
    "\n",
    "Esta vez no necesitamos toda la lista de usuarios, sólo necesitamos uno, ya que estamos probando una cosa concreta y tenemos la prueba anterior para asegurarnos de que estamos generando el fichero correctamente con todos los usuarios. Recuerda, intenta siempre minimizar el trabajo que haces dentro de una prueba.\n",
    "\n",
    "Así que usamos `min_user`, y ponemos una bonita coma en su nombre. Luego repetimos el procedimiento, que es muy similar al de la prueba anterior, y finalmente nos aseguramos de que el nombre se pone en el archivo CSV rodeado de comillas dobles. Esto es suficiente para que cualquier buen analizador CSV entienda que no tiene que romper la coma dentro de las comillas dobles.\n",
    "\n",
    "Ahora, queremos una prueba más, que tiene que comprobar que cuando el archivo ya existe y no queremos anularlo, nuestro código no lo hará.\n",
    "\n",
    "Este es un bonito `test`, porque nos permite mostrarte cómo puedes decirle a `pytest` que esperas que una llamada a una función lance una excepción. Lo hacemos en el gestor de contexto que nos da `pytest.raises`, al que alimentamos con la excepción que esperamos de la llamada que hacemos dentro del cuerpo de ese gestor de contexto. Si la excepción no se lanza, la prueba fallará.\n",
    "\n",
    "Nos gusta ser minuciosos en nuestras pruebas, así que no queremos detenernos ahí. También hacemos una aserción sobre el mensaje, utilizando el práctico ayudante `err.match`. Observe que no necesitamos utilizar una sentencia `assert` al llamar a `err.match`. Si el argumento no coincide, la llamada lanzará un `AssertionError`, provocando el fallo de la prueba. También necesitamos escapar la versión de cadena de archivo_existente porque en Windows, las rutas tienen barras invertidas, lo que confundiría la expresión regular que introducimos en `err.match()`.\n",
    "\n",
    "Por último, nos aseguramos de que el archivo todavía contiene su contenido original (que es por lo que creamos el fixture archivo_existente) abriéndolo, y comparando todo su contenido con la cadena que debería ser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestExport:\n",
    "    \"\"\"Test behavior of 'export' function. \"\"\"\n",
    "    \n",
    "    @pytest.fixture\n",
    "    def csv_file(self, tmp_path):\n",
    "        \"\"\"Yield a filename in a temporary folder.\n",
    "        Due to how pytest 'tmp_path' fixture works, the file does\n",
    "        not exist yet.\n",
    "        \"\"\"\n",
    "        yield tmp_path / \"out.csv\"\n",
    "\n",
    "    @pytest.fixture\n",
    "    def existing_file(self, tmp_path):\n",
    "        \"\"\"Create a temporary file and put some content in it. \"\"\"\n",
    "        existing = tmp_path / 'existing.csv'\n",
    "        existing.write_text('Please leave me alone...')\n",
    "        yield existing\n",
    "\n",
    "    def test_export(self, users, csv_file):\n",
    "        export(csv_file, users)\n",
    "        text = csv_file.read_text()\n",
    "        assert (\n",
    "            'email,name,age,role\\n'\n",
    "            'minimal@example.com,Primus Minimus,18,\\n'\n",
    "            'full@example.com,Maximus Plenus,65,emperor\\n'\n",
    "        ) == text\n",
    "\n",
    "    def test_export_quoting(self, min_user, csv_file):\n",
    "        min_user['name'] = 'A name, with a comma'\n",
    "        export(csv_file, [min_user])\n",
    "        text = csv_file.read_text()\n",
    "        assert (\n",
    "            'email,name,age,role\\n'\n",
    "            'minimal@example.com,\"A name, with a comma\",18,\\n'\n",
    "        ) == text\n",
    "\n",
    "    def test_does_not_overwrite(self, users, existing_file):\n",
    "        with pytest.raises(IOError) as err:\n",
    "            export(existing_file, users, overwrite=False)\n",
    "        err.match(\n",
    "            r\"'{}' already exists\\.\".format(\n",
    "                re.escape(str(existing_file))\n",
    "            )\n",
    "        )\n",
    "        # let's also verify the file is still intact\n",
    "        assert existing_file.read() == 'Please leave me alone...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consideraciones finales\n",
    "Antes de pasar al siguiente tema, terminemos con algunas consideraciones.\n",
    "\n",
    "Primero, esperamos que hayas notado que no hemos probado todas las funciones que escribimos. Específicamente, no probamos `get_valid_users`, `validate`, y `write_csv`. La razón es que estas funciones ya están implícitamente probadas por nuestro conjunto de pruebas. Hemos probado `is_valid()` y `export()`, lo que es más que suficiente para asegurarnos de que nuestro esquema valida los usuarios correctamente, y la función `export()` se encarga de filtrar los usuarios no válidos correctamente, respetando los archivos existentes cuando es necesario, y escribiendo un CSV adecuado. Las funciones que no hemos probado son las internas; proporcionan lógica que participa en hacer algo que hemos probado a fondo de todos modos.\n",
    "\n",
    "Tener en cuenta que si agregamos más pruebas podría generar inconvenientes: ya que, cuanto más probemos, será más difícil refactorizar ese código. Tal y como está ahora, podríamos decidir fácilmente renombrar `validate()`, y no tendríamos que cambiar ninguna de las pruebas que escribimos. Si lo piensas, tiene sentido, porque mientras validate() proporcione una validación correcta a la función get_valid_users(), realmente no necesitamos saberlo.\n",
    "\n",
    "Si, en cambio, hubiéramos escrito tests para la función `validate()`, tendríamos que cambiarlos si decidiéramos renombrarla (o cambiar su firma, por ejemplo).\n",
    "\n",
    "Entonces, ¿qué es lo correcto? ¿Probar o no probar? Depende de ti. Hay que encontrar el equilibrio adecuado. Nuestra opinión personal al respecto es que todo debe probarse a fondo, ya sea directa o indirectamente. Y tratamos de escribir el menor conjunto de pruebas posible que garantice eso. De esta manera, tendremos un gran conjunto de pruebas en términos de cobertura, pero no más grande de lo necesario. Tenemos que mantener esas pruebas.\n",
    "\n",
    "Esperamos que este ejemplo haya tenido sentido para ti; creemos que nos ha permitido tocar los temas importantes.\n",
    "\n",
    "Si echas un vistazo al código, encontrarás un par de clases de prueba adicionales que te mostrarán lo diferentes que habrían sido las pruebas si hubiéramos decidido ir hasta el final con los mocks. Asegúrate de leer ese código y entenderlo bien. Es bastante sencillo y te ofrecerá una buena comparación con el enfoque que te hemos mostrado aquí.\n",
    "\n",
    "Asegúrese de ejecutar `$ pytest test` desde dentro de la terminal ubicandote en la carpeta donde están los scripts. `pytest` escanea sus archivos y carpetas, buscando módulos que empiecen o terminen con `test_`, como `test_*.py`, o `*_test.py`. Dentro de esos módulos, coge funciones prefijadas por test o métodos prefijados por test dentro de clases prefijadas por test (puedes leer la especificación completa en la documentación de pytest). Como puede ver, se ejecutaron 132 pruebas en menos de medio segundo, y todas tuvieron éxito. Le sugerimos encarecidamente que compruebe este código y juegue con él. Cambia algo en el código y comprueba si alguna prueba se rompe. Entender por qué se rompe. ¿Es algo importante que significa que la prueba no es lo suficientemente buena? ¿O se trata de una tontería que no debería romper la prueba? Todas estas preguntas, aparentemente inocuas, te ayudarán a profundizar en el arte de las pruebas.\n",
    "\n",
    "También le sugerimos que estudie el módulo `unittest` y la biblioteca `pytest`. Estas son herramientas que utilizarás todo el tiempo, por lo que necesitas estar muy familiarizado con ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desarrollo basado en pruebas\n",
    "Hablemos brevemente del desarrollo basado en pruebas (TDD por sus siglás en inglés). Es una metodología que fue redescubierta por Kent Beck, quien escribió Test-Driven Development by Example, Addison Wesley, 2002, que te animamos a leer si quieres conocer los fundamentos de esta materia.\n",
    "\n",
    "TDD es una metodología de desarrollo de software que se basa en la repetición continua de un ciclo de desarrollo muy corto.\n",
    "\n",
    "En primer lugar, el desarrollador escribe una prueba y la hace ejecutar. Se supone que la prueba comprueba una característica que aún no forma parte del código. Tal vez sea una nueva característica que se debe agregar, o algo que se debe eliminar o modificar. Ejecutar la prueba hará que falle y, debido a esto, esta fase se llama Rojo.\n",
    "\n",
    "Cuando se produce un error en la prueba, el desarrollador escribe la cantidad mínima de código para que se supere. Cuando la ejecución de la prueba tiene éxito, tenemos la llamada fase verde. En esta fase, está bien escribir código que haga trampa, solo para que la prueba pase. Esta técnica se llama fingir hasta que lo consigas. En una segunda iteración del ciclo TDD, las pruebas se enriquecen con diferentes casos extremos, y el código de trampa debe reescribirse con la lógica adecuada. La adición de otros casos de prueba a veces se denomina triangulación.\n",
    "\n",
    "La última parte del ciclo es donde el desarrollador se encarga de refactorizar el código y las pruebas hasta que están en el estado deseado. Esta última fase se denomina Refactorización.\n",
    "\n",
    "Por lo tanto, el mantra TDD es Red-Green-Refactor.\n",
    "\n",
    "Al principio, puede parecer raro escribir pruebas antes del código. Sin embargo, si te aferras a él y te obligas a aprender esta forma de trabajar un poco contraria a la intuición, en algún momento sucede algo casi mágico, y verás que la calidad de tu código aumenta de una manera que no sería posible de otra manera.\n",
    "\n",
    "Cuando escribimos nuestro código antes de las pruebas, tenemos que cuidar de lo que el código tiene que hacer y de cómo tiene que hacerlo, ambas cosas a la vez. Por otro lado, cuando escribimos pruebas antes del código, podemos concentrarnos solo en la parte del qué mientras las estamos escribiendo. Cuando escribamos el código después, tendremos que ocuparnos principalmente de cómo el código tiene que implementar lo que requieren las pruebas. Este cambio de enfoque permite que nuestras mentes se concentren en las partes del qué y el cómo por separado, lo que produce un aumento de la capacidad intelectual que puede resultar bastante sorprendente.\n",
    "\n",
    "Hay varios otros beneficios que se derivan de la adopción de esta técnica:\n",
    "- **Refactorizará con mucha más confianza:** Las pruebas se romperán si introduces errores. Además, una refactorización arquitectónica también se beneficiará de tener pruebas que actúen como guardianes.\n",
    "- **El código será más legible:** Esto es crucial en una época en la que codificar es una actividad social y todo desarrollador profesional pasa mucho más tiempo leyendo código que escribiéndolo.\n",
    "- **El código estará mejor acoplado y será más fácil de probar y mantener:** Escribir primero las pruebas obliga a pensar más profundamente en la estructura del código.\n",
    "- **Escribir primero las pruebas requiere una mejor comprensión de los requisitos de negocio:** Si su comprensión de los requisitos es deficiente, escribir una prueba le resultará extremadamente difícil y esta situación actuará como un centinela para usted.\n",
    "- **Tener todo probado por unidades significa que el código será más fácil de depurar:** Además, las pruebas pequeñas son perfectas para proporcionar documentación alternativa. El inglés puede ser engañoso, pero cinco líneas de Python en una prueba sencilla son muy difíciles de malinterpretar.\n",
    "- **Mayor velocidad:** Es más rápido escribir pruebas y código que escribir primero el código y luego perder tiempo depurándolo. Si no escribes pruebas, probablemente entregues el código antes, pero entonces tendrás que rastrear los errores y solucionarlos (y, ten por seguro, que habrá errores). El tiempo combinado que se tarda en escribir el código y luego depurarlo suele ser mayor que el tiempo que se tarda en desarrollar el código con TDD, donde tener pruebas ejecutándose antes de escribir el código garantiza que el número de errores en él será mucho menor que en el otro caso.\n",
    "\n",
    "Por otro lado, existen algunas deficiencias de esta técnica:\n",
    "- **Es necesario que toda la empresa crea en ello:** De lo contrario, tendrás que discutir constantemente con tu jefe, que no entenderá por qué tardas tanto en entregar. La verdad es que, a corto plazo, puede que tardes un poco más en entregar, pero a largo plazo, ganas mucho con TDD. Sin embargo, es bastante difícil ver el largo plazo porque no está bajo nuestras narices como lo está el corto plazo. En nuestra carrera hemos librado batallas con jefes testarudos para poder codificar usando TDD. A veces ha sido doloroso, pero siempre ha merecido la pena, y nunca nos hemos arrepentido porque, al final, siempre se ha apreciado la calidad del resultado.\n",
    "- **Si no entiendes los requisitos del negocio, esto se reflejará en las pruebas que escribas, y por lo tanto se reflejará también en el código:** Este tipo de problema es bastante difícil de detectar hasta que se realizan las pruebas de aceptación del usuario, pero una cosa que puedes hacer para reducir la probabilidad de que ocurra es emparejarte con otro desarrollador. El emparejamiento exigirá inevitablemente discutir los requisitos de la empresa, y la discusión aportará clarificación, lo que ayudará a escribir pruebas correctas.\n",
    "- **Las pruebas mal escritas son difíciles de mantener:** Esto es un hecho. Las pruebas con demasiados mocks o con suposiciones adicionales o datos mal estructurados pronto se convertirán en una carga. No dejes que esto te desanime; simplemente sigue experimentando y cambia la forma de escribirlas hasta que encuentres una manera que no requiera una enorme cantidad de trabajo cada vez que toques tu código.\n",
    "  \n",
    "En esta sesión hemos explorado el mundo de las pruebas.\n",
    "\n",
    "Intentamos darte una visión general bastante completa de las pruebas, especialmente de las pruebas unitarias, que es el tipo de pruebas que realiza principalmente un desarrollador. Esperamos haber logrado transmitir el mensaje de que las pruebas no son algo que esté perfectamente definido y que puedas aprender de un libro. Hay que experimentar mucho antes de sentirse cómodo. De todos los esfuerzos que un programador debe hacer en términos de estudio y experimentación, diríamos que el testing es el más importante."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
